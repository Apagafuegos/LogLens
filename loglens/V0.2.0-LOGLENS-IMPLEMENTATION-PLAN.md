# V0.2.0 LogLens Implementation Plan

## Overview
Enhance LogLens with improved export functionality, dynamic model configuration, user context support, configurable timeouts, better progress visualization, project management improvements, and comprehensive error analytics.

## Core Architecture Changes

### 1. Enhanced Export System
**Backend Changes:**
- Fix existing export formats (HTML, JSON, CSV currently non-functional)
- Add PDF export implementation using `wkhtmltopdf` or `headless_chrome`
- Add Markdown export functionality
- Implement export templates system for consistent formatting
- Add export progress tracking and streaming for large analyses

**Current Export Issues:**
- Routes have inconsistent patterns - standardize to `/projects/:project_id/analyses/:analysis_id/export/:format`
- HTML export has basic implementation but needs proper data rendering
- JSON export needs proper structure with all analysis components
- CSV export needs improved format with proper headers
- PDF export is just a placeholder returning HTML notice
- MD export is completely missing

**Frontend Changes:**
- Update ExportOptions component to include all 4 formats (JSON, HTML, MD, PDF)
- Fix API endpoint calls to match backend routes
- Add export progress indicators and error handling
- Update API service to handle all export formats properly

**Dependencies to Add:**
```toml
wkhtmltopdf = "0.5"  # For PDF generation
pulldown-cmark = "0.9"  # For markdown processing
```

### 2. Dynamic Model Configuration System
**Core Provider Architecture:**
- Add `get_available_models()` method to AIProvider trait
- Implement model fetching endpoints for each provider (OpenRouter, OpenAI, Claude, Gemini)
- Create model caching system to avoid repeated API calls
- Add model metadata (capabilities, context limits, pricing tiers)

**Settings Enhancement:**
- Extend Settings model with model selection fields
- Add model selection dropdown in settings UI
- Implement model validation before analysis starts
- Replace all hardcoded model references with dynamic selection

**Database Changes:**
```sql
-- New settings fields
ALTER TABLE settings ADD COLUMN selected_model TEXT;
ALTER TABLE settings ADD COLUMN available_models TEXT; -- JSON array cache
ALTER TABLE settings ADD COLUMN models_last_fetched DATETIME;
```

### 3. User Context Integration
**Request Flow Enhancement:**
- Add context field to AnalysisRequest model (max 2000 characters)
- Modify AI provider prompts to incorporate user context
- Add context validation and sanitization
- Implement context templating system

**UI Components:**
- Add expandable context textarea in analysis request forms
- Implement character counter and validation
- Add context suggestions based on log patterns
- Create context templates for common scenarios

### 4. Configurable Timeout System
**Provider Architecture:**
- Replace fixed 30s timeout with configurable system
- Add timeout field to Settings model (default 300s, range 60s-1800s)
- Implement timeout validation in analysis requests
- Add timeout progress indicators

**Database Changes:**
```sql
ALTER TABLE settings ADD COLUMN analysis_timeout_seconds INTEGER DEFAULT 300;
```

### 5. Enhanced Analysis Progress System
**Progress Tracking:**
- Extend AnalysisStatus with intermediate states (Initializing, Processing, Finalizing)
- Add progress percentage tracking
- Implement real-time progress updates via WebSocket
- Create detailed progress logs for debugging

**UI Improvements:**
- Design new progress screen with animated indicators
- Add progress breakdown by analysis phases
- Implement cancellation functionality
- Show estimated time remaining based on historical data

### 6. Project Management Enhancement
**Dashboard Improvements:**
- Add project deletion confirmation dialog
- Implement bulk project operations
- Add project archiving (soft delete) option
- Create project usage statistics

**Safety Features:**
- Enhanced cascade delete validation
- Project backup before deletion
- Undo functionality for recent deletions
- Usage warnings for active projects

### 7. Comprehensive Error Analytics
**Error Categorization System:**
- Enhance ErrorCategory enum with detailed subcategories
- Implement automatic error pattern recognition
- Add error frequency tracking and trending
- Create error correlation engine

**Visualization Components:**
- Error frequency charts (pie charts, time series)
- Error category distribution graphs
- Top error patterns dashboard
- Error correlation network diagrams

**Data Models:**
```sql
-- Enhanced error tracking
CREATE TABLE error_instances (
    id TEXT PRIMARY KEY,
    analysis_id TEXT NOT NULL,
    category TEXT NOT NULL,
    subcategory TEXT,
    pattern_hash TEXT,
    frequency_in_analysis INTEGER,
    first_occurrence DATETIME,
    last_occurrence DATETIME,
    severity_score REAL,
    FOREIGN KEY (analysis_id) REFERENCES analyses(id)
);

CREATE INDEX idx_error_instances_category ON error_instances(category);
CREATE INDEX idx_error_instances_pattern ON error_instances(pattern_hash);
```

## Implementation Strategy

### Phase 1: Export System Fix (Priority)
1. Fix existing export handlers (HTML, JSON, CSV)
2. Implement PDF export with proper PDF generation
3. Add Markdown export functionality
4. Update frontend export components
5. Standardize export API routes

### Phase 2: Core Infrastructure
1. Enhanced AI provider architecture with model fetching
2. Settings system expansion
3. Database schema updates
4. Basic timeout configuration

### Phase 3: User Experience
1. User context integration
2. Enhanced progress tracking system
3. Project management enhancements

### Phase 4: Analytics & Visualization
1. Error categorization engine
2. Analytics dashboard components
3. Chart and graph implementations
4. Performance optimizations

## Technical Considerations

### Performance
- Export data streaming for large analyses (>10MB)
- Model list caching (24-hour TTL)
- Lazy loading for dashboard components
- WebSocket connection pooling for progress updates
- Database indexing for error analytics queries
- Export result caching for repeated requests

### Security
- Context input sanitization (XSS prevention)
- API key secure storage for model fetching
- Rate limiting for model list requests
- Input validation for all new fields
- Export size limits and validation

### Compatibility
- Backward compatibility for existing analyses
- Migration scripts for database changes
- Graceful degradation for unsupported models
- Progressive enhancement for new features

### Export System Specifications
**Template System:**
- Create reusable export templates for consistent formatting
- Implement template caching to avoid regeneration
- Add template optimization for large analyses

**Data Structure for All Exports:**
- Analysis metadata (ID, provider, status, timestamps)
- Error patterns and categories with frequency
- Performance metrics with visualization data
- Correlations and recommendations
- Raw log analysis results

**Error Handling:**
- Proper error responses for failed exports
- Retry mechanism for transient failures
- Export validation before generation
- Export progress tracking and cancellation

### Testing Strategy
- Unit tests for new provider methods and export formats
- Integration tests for export functionality and API endpoints
- UI tests for enhanced progress screens and export components
- Performance tests for analytics queries and large exports
- Frontend tests for export UI functionality

This plan provides a systematic approach to implementing all requested features while maintaining code quality and system stability, with focused attention on making export functionality fully operational.